{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example notebook. Invokes the NVIDIA NIM\n",
    "\n",
    "Make sure to use the url as shown on the NVIDIA serving model end-point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "nim_url = \"https://nvidia-nim-model-llama3-demo.nvidia-nim-openshift-ai-demo.svc.cluster.local\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the list of available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(nim_url + \"/v1/models\", verify=False)\n",
    "print(json.dumps(response.json()['data'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a chat request to the target model, use the model from previous output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "payload = {\n",
    "    \"model\": \"meta/llama-3.1-8b-instruct\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is Hitachi VSP One SDS?\"\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 1,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": False\n",
    "}\n",
    "response = requests.post(nim_url + \"/v1/chat/completions\", verify=False, headers=headers, json=payload)\n",
    "print(response.json()['choices'][0]['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
